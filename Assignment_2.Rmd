---
output: 
  pdf_document: 
    extra_dependencies: flafter
    fig_caption: yes
    toc_depth: 2
    highlight: tango
---
```{r, echo=FALSE}
knitr::opts_chunk$set(fig.pos = "!H", out.extra = "")
```

## Assignment - 2 - Aftab Alam & Talha Zahid
### Introduction
This assignment has tried to find the probability of a hotel being highly rated in Madrid in November 2017 on weekdays based on the data taken from **[OSF-Price]("https://osf.io/p6tyr/")** and **[OSF-Features]("https://osf.io/utwjs/")** website.

### Data
Firstly, we have created a binary variable where the highly_rated variable, where highly_rated = 1 if rating >= 4, else 0. In order to check correlation between different variables with the highly_rated, we created a correlation heat map. As the variables price, distance, and stars seemed to have high correlation with the ratings, we decided to move forward with these 3 variables. The price variable had a near log-normal distribution, so we decided to take the log of price which gave us a Normal Distribution. In order to see if we are required to use splines, we checked the lowess curves for the 3 variables. For stars we decided to use splines at 3, 3.5, and 4 and for distance we used splines at 1, 3.5, and 5, graphs for these 2 variables are shown in the appendix. 

### Analysis
We first ran an LPM model where we regressed highly rated distance, stars, and the log price. As mentioned above, we added splines to the distance and stars variables. The coefficients of LPM gave us 4 significant coefficients, stars and log price. However, when we looked at the predicted probabilities of the model, there were values of above 1, which cannot be a case in probabilities.

Hence, we decided to run logit and probit models to limit our predicted models between 0 and 1. As expected, the predicted probabilities were between 0 and 1 for these models, also shown in the graph in the appendix.

Moreover, since the coefficients of these 2 models can be interpreted directly, we then estimated the probit and logit regressions to calculate the corresponding marginal effects. Since these the coefficients from these can be interpreted similar to an LPM model.

In terms of the direction of the coefficients, we are getting the same directions for all variables across models except for the spline where stars for a hotel are less than 3; for this LPM is giving a positive value as opposed to a negative value in the other models. Regardless, this coefficients is not significant across all the models.

Reading the significant coefficients from the LPM, for a hotel rated between 3 and 3.5 stars, the probability of getting a high rating is 26% when the star is higher by 0.5 unit. The same variable in the logit-AME model, this probability is 35%. The variable is not significant under the probit-AME model.

For a hotel with stars between 3.5 and 4, the probability of getting a high rating is -17% when the star is higher by 0.5 unit. The same variable shows a probability of -15% under the logit-AME and probit-AME models. For a hotel with stars 4 and above, the probability of getting a high rating is -15% when when the star is higher by 1 unit. However, the coefficient is not significant in the other models although the direction is same.

The distance variable's coefficients are not significant across the models and and their sign oscillates between negative and positive for the 4 splines, respectively. 

With regards to the log(price) variable, the coefficients are significant at 99.9% across the models. As per the LPM, the probability of a hotel being highly rated is 40% when the price is higher by 1%. The probabilities are similar in the probit-AME and logit-AME are  similar with a probability of 44%.

### Conclusion
Based on the models we have run, we are confident in establishing that the probability of getting a high rating for hotel is higher for higher prices. This might be because hotels that are priced higher tend to have better services in general, hence receiving a higher rating, however, we need to further refine our models to get a better relationship between price and high rating. With regards to stars, our models show that for hotels with stars less 3.5 tend to have a positive probability of getting high ratings for a hotel with more stars, however, for hotels with more than 4 stars tend to have a negative probability of getting high ratings for a hotel with more stars. A plausible reason could be that for hotels with more stars, higher than 4, the expectations of customers tend to increase and they tend to rate the hotels more critically.

Moreover, our models did not establish any significant relationship between the probability of highly rated and distance of the hotel from the city center, but the signs of the coefficients suggest a hotel near the center has a higher probability of getting a better rating. 

Overall, we would caution before generalizing these results as we believe more research is needed in terms of internal validity and external validity to not just imply a relationship but also for external validity.



```{r, echo=FALSE, message=FALSE, warning=FALSE}

rm(list=ls())

# packages
library(tidyverse)
library(modelsummary)
library(fixest)
library(ggpubr)
library(lspline)
#install.packages("mfx")
library(mfx)
library(reshape2)
library(data.table)
library(kableExtra)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}
# Loading the data

hotels_europe_price <- read_csv("https://osf.io/p6tyr/download")
hotels_europe_features <- read_csv("https://osf.io/utwjs/download")

# Join them by hotel_id
data <- left_join(hotels_europe_price, hotels_europe_features, by = "hotel_id")
rm(hotels_europe_price,hotels_europe_features)

# Filtering the data and selecting the city - 

unique(data$city_actual)
unique(data$year)

# Choosing madrid as the city and 2017 as the year

madrid <- data %>% 
  filter(accommodation_type == "Hotel") %>% 
  filter( year == 2017) %>% 
  filter(city_actual == "Madrid") %>% 
  filter(!is.na(rating))
####
unique(madrid$month)
unique(madrid$weekend)

# Further filtering the dataset on month and weekend/weekday data

madrid <- madrid %>% 
  filter(month == 11 , weekend == 0)
####
summary(madrid$price) 

# Checking to see any extreme values in the price variable.

ggplot(data = madrid , aes(x = price)) +
  geom_point(aes(y = rating))

# Filtering out the extreme value of prices above 500, and NA values for stars and distance

madrid <- madrid %>% 
  filter(price < 500) %>% 
  filter(!is.na(stars)) %>% 
  filter(!is.na(distance))
  
madrid <- data.table::data.table(madrid)

```


```{r, echo=FALSE}

# Creating the highly_rated variable, where highly_rated = 1 if rating >= 4, else 0

madrid$highly_rated <- ifelse(madrid$rating>=4, 1, 0)

```


```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

# Checking correlations of variables with highly_rated

numeric_df <- keep( madrid , is.numeric ) 

cT <- round( cor( numeric_df , use = "complete.obs") , 2 )
# create a lower triangular matrix
cT[ upper.tri( cT ) ] <- NA
# Put it into a tibble format
melted_cormat <- melt( cT , na.rm = TRUE)
# Now we can create a heat-map
 cor_matrix <- ggplot( data = melted_cormat, aes( Var2 , Var1 , fill = value ) )+
  geom_tile( color = "white" ) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlation") +
  theme_bw()+ 
  theme( axis.text.x = element_text(angle = 45, vjust = 1, 
                                    size = 10, hjust = 1))+
  labs(y="",x="")+
  coord_fixed()

cor_matrix

# Based on the correlation matrix, it seems like the variable highly_rated is positively related to price and stars, whereas it is negatively related to 
# offer, scarce_room, and distance. However, for the purpose of this assignment, we are going forward with the variables price, stars, and distance.

####
ggplot(data = madrid, aes(x=price))+
  geom_density()

ggplot(data = madrid, aes(x=log( price )))+
  geom_density()

# Since the price variable is a little skewed toward the y-axis, we are taking the log price as it gives a near normal distribution

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

# Checking lowess curves for the three dependent variables to decide on using splines or not

graph_dist <- ggplot(data = madrid, aes(x=distance, y=highly_rated))+
  geom_smooth(formula = y~x, method = "loess")

graph_star <- ggplot(data = madrid, aes(x=stars, y=highly_rated))+
  geom_smooth(formula = y~x, method = "loess")

graph_price <- ggplot(data = madrid, aes(x=log( price ), y=highly_rated))+
  geom_smooth(formula = y~x, method = "loess")

P95 <- function(x){ quantile(x,.95,na.rm=T)}
P5 <- function(x){ quantile(x,.05,na.rm=T)}
ds <- datasummary( highly_rated + distance + stars + price + log( price ) ~ Mean + SD + Min + Max + Median + P5 + P95 + N , data = madrid )
ds
```


```{r, echo=FALSE, include=FALSE}

lpm1 <- feols(highly_rated ~ stars + distance + log (price), data=madrid, vcov = "hetero")

lpm <- feols(highly_rated ~ lspline(stars,c(3,3.5,4))  + lspline(distance, c(1,3.5,5)) + log (price), data=madrid, vcov = "hetero")


madrid$pred_lpm <- predict(lpm)

summary(madrid$pred_lpm)

# Since the max value of predicted values' probability is above 1, which cannot be a case in probabilities, we need to run probit/logit regressions.

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

# logit regressions

logit <- glm(highly_rated ~ lspline(stars,c(3,3.5,4))  + lspline(distance, c(1,3.5,5))  + log( price ), data=madrid, family='binomial'(link = "logit"))
#summary(logit)
#glance(logit)


# predicted probabilities 
madrid$pred_logit <- predict.glm(logit, type="response")
fitted(logit) == data$pred_logit
summary(madrid$pred_logit)
# The predicted values are now between 0 and 1.

logit_marg <- logitmfx(highly_rated ~ lspline(stars,c(3,3.5,4))  + lspline(distance, c(1,3.5,5))  + log( price ), data=madrid, atmean=FALSE)


```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

# probit regression

probit <- glm(highly_rated ~ lspline(stars,c(3,3.5,4))  + lspline(distance, c(1,3.5,5))  + log( price ), data=madrid, family=binomial(link="probit"))
# predicted probabilities 
madrid$pred_probit<- predict.glm(probit, type="response") 
summary(madrid$pred_probit)
# probit marginal differences
probit_marg <- probitmfx(highly_rated ~ lspline(stars,c(3,3.5,4))  + lspline(distance, c(1,3.5,5))  + log( price ), data=madrid, atmean=F)


```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}

varname_report <- c("(Intercept)" = "Intercept",
                   "lspline(stars, c(3, 3.5, 4))1" = "stars (<3)",
                   "lspline(stars, c(3, 3.5, 4))2" = "stars (>=3, <3.5)",
                   "lspline(stars, c(3, 3.5, 4))3" = "stars (>=3.5)",
                   "lspline(distance, c(1, 3.5, 5))1" = "distance (<1)",
                   "lspline(distance, c(1, 3.5, 5))2" = "distance (>=1, <3.5)",
                   "lspline(distance, c(1, 3.5, 5))3" = "distance (>=3.5)",
                   "log(price)" = "log(price)")

cm <- c('(Intercept)' = 'Constant')

summarry_reg <- msummary(list("lpm" = lpm , "logit" = logit , "logit_marg" = logit_marg , "probit" = probit ,"probit_marg"= probit_marg),
         fmt="%.3f",
         gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC|R2|PseudoR2',
         stars=c('*' = .05, '**' = .01, '***' = .001),
         coef_rename = c("(Intercept)" = "Intercept",
                   "lspline(stars, c(3, 3.5, 4))1" = "stars (<3)",
                   "lspline(stars, c(3, 3.5, 4))2" = "stars (>=3, <3.5)",
                   "lspline(stars, c(3, 3.5, 4))3" = "stars (>=3.5, <4)",
                   "lspline(stars, c(3, 3.5, 4))4" = "stars (>=4)",
                   "lspline(distance, c(1, 3.5, 5))1" = "distance (<1)",
                   "lspline(distance, c(1, 3.5, 5))2" = "distance (>=1, <3.5)",
                   "lspline(distance, c(1, 3.5, 5))3" = "distance (>=3.5, <5)",
                   "lspline(distance, c(1, 3.5, 5))4" = "distance (>=5)",
                   "log(price)" = "log(price)")
         
)


```

```{r, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE}
g5 <- ggplot(data = madrid) +
  geom_smooth(aes(x=pred_lpm, y=pred_probit, color="Probit"), size=0.5,  shape=16) +
  geom_smooth(aes(x=pred_lpm, y=pred_logit,  color="Logit"), size=0.5,  shape=16) +
  geom_line(aes(x=pred_lpm, y=pred_lpm,    color="45 Degree line"), size=0.5) +
  labs(title = "Predicted Probabilities", x = "Predicted probability of Highly Rated (LPM)", y="Predicted probability (Logit,Probit) ")+
  scale_y_continuous(expand = c(0.00,0.0), limits = c(0.1,1), breaks = seq(0,1,0.1)) +
  scale_x_continuous(expand = c(0.00,0.0), limits = c(0.25,1), breaks = seq(0,1,0.1)) +
  scale_color_manual(name = "", values=c("#D40C0C", "#03577B","#00C20F")) +
  ggthemes::theme_economist()+
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold",
    hjust = 0.5),
    axis.title.y = element_text(face = "bold", vjust = 4),
    axis.title.x = element_text(face = "bold", vjust = -2)
  )
```

## Appenddix

Data summary for interested variables
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.show="hold"}
ds %>% 
      kable_styling(latex_options = c("HOLD_position", "striped"),stripe_color = "gray!6" )

```


Correlation Matrix

```{r, echo=FALSE, warning=FALSE, message=FALSE,  fig.align='center', fig.height=3.7, fig.show="hold"}
cor_matrix
```


Lowess curves for distance and stars against highly_rated

```{r, echo=FALSE, warning=FALSE, message=FALSE, figures-side, fig.show="hold", out.width="50%"}
graph_dist

graph_star

```


Predicted values from Logit and Probit against predicted values from lpm

```{r, echo=FALSE, warning=FALSE, message=FALSE,  fig.align='center', fig.height= 4 ,fig.width= 6 , fig.show="hold"}
g5

```

Regression tables
```{r, echo=FALSE, warning=FALSE, message=FALSE,  fig.pos="h"}
summarry_reg  %>% 
      kable_styling(latex_options = c("HOLD_position", "striped","scale_down"),stripe_color = "gray!6" )

```


